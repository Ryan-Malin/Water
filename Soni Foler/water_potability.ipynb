{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file and load\n",
    "water_df = pd.read_csv(\"water_potability.csv\")\n",
    "water_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3276 entries, 0 to 3275\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ph               2785 non-null   float64\n",
      " 1   Hardness         3276 non-null   float64\n",
      " 2   Solids           3276 non-null   float64\n",
      " 3   Chloramines      3276 non-null   float64\n",
      " 4   Sulfate          2495 non-null   float64\n",
      " 5   Conductivity     3276 non-null   float64\n",
      " 6   Organic_carbon   3276 non-null   float64\n",
      " 7   Trihalomethanes  3114 non-null   float64\n",
      " 8   Turbidity        3276 non-null   float64\n",
      " 9   Potability       3276 non-null   int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 256.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Know about the dataset\n",
    "water_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1998\n",
       "1    1278\n",
       "Name: Potability, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Potability value count\n",
    "label_count = water_df[\"Potability\"].value_counts() \n",
    "label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>9.445130</td>\n",
       "      <td>145.805402</td>\n",
       "      <td>13168.529156</td>\n",
       "      <td>9.444471</td>\n",
       "      <td>310.583374</td>\n",
       "      <td>592.659021</td>\n",
       "      <td>8.606397</td>\n",
       "      <td>77.577460</td>\n",
       "      <td>3.875165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>9.024845</td>\n",
       "      <td>128.096691</td>\n",
       "      <td>19859.676476</td>\n",
       "      <td>8.016423</td>\n",
       "      <td>300.150377</td>\n",
       "      <td>451.143481</td>\n",
       "      <td>14.770863</td>\n",
       "      <td>73.778026</td>\n",
       "      <td>3.985251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>NaN</td>\n",
       "      <td>169.974849</td>\n",
       "      <td>23403.637304</td>\n",
       "      <td>8.519730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>475.573562</td>\n",
       "      <td>12.924107</td>\n",
       "      <td>50.861913</td>\n",
       "      <td>2.747313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>6.800119</td>\n",
       "      <td>242.008082</td>\n",
       "      <td>39143.403329</td>\n",
       "      <td>9.501695</td>\n",
       "      <td>187.170714</td>\n",
       "      <td>376.456593</td>\n",
       "      <td>11.432466</td>\n",
       "      <td>73.777275</td>\n",
       "      <td>3.854940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>7.174135</td>\n",
       "      <td>203.408935</td>\n",
       "      <td>20401.102461</td>\n",
       "      <td>7.681806</td>\n",
       "      <td>287.085679</td>\n",
       "      <td>315.549900</td>\n",
       "      <td>14.533510</td>\n",
       "      <td>74.405616</td>\n",
       "      <td>3.939896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>4.668102</td>\n",
       "      <td>193.681735</td>\n",
       "      <td>47580.991603</td>\n",
       "      <td>7.166639</td>\n",
       "      <td>359.948574</td>\n",
       "      <td>526.424171</td>\n",
       "      <td>13.894419</td>\n",
       "      <td>66.687695</td>\n",
       "      <td>4.435821</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>7.808856</td>\n",
       "      <td>193.553212</td>\n",
       "      <td>17329.802160</td>\n",
       "      <td>8.061362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>392.449580</td>\n",
       "      <td>19.903225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.798243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>9.419510</td>\n",
       "      <td>175.762646</td>\n",
       "      <td>33155.578218</td>\n",
       "      <td>7.350233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>432.044783</td>\n",
       "      <td>11.039070</td>\n",
       "      <td>69.845400</td>\n",
       "      <td>3.298875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>5.126763</td>\n",
       "      <td>230.603758</td>\n",
       "      <td>11983.869376</td>\n",
       "      <td>6.303357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>402.883113</td>\n",
       "      <td>11.168946</td>\n",
       "      <td>77.488213</td>\n",
       "      <td>4.708658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>7.874671</td>\n",
       "      <td>195.102299</td>\n",
       "      <td>17404.177061</td>\n",
       "      <td>7.509306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>327.459760</td>\n",
       "      <td>16.140368</td>\n",
       "      <td>78.698446</td>\n",
       "      <td>2.309149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1278 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
       "250   9.445130  145.805402  13168.529156     9.444471  310.583374   \n",
       "251   9.024845  128.096691  19859.676476     8.016423  300.150377   \n",
       "252        NaN  169.974849  23403.637304     8.519730         NaN   \n",
       "253   6.800119  242.008082  39143.403329     9.501695  187.170714   \n",
       "254   7.174135  203.408935  20401.102461     7.681806  287.085679   \n",
       "...        ...         ...           ...          ...         ...   \n",
       "3271  4.668102  193.681735  47580.991603     7.166639  359.948574   \n",
       "3272  7.808856  193.553212  17329.802160     8.061362         NaN   \n",
       "3273  9.419510  175.762646  33155.578218     7.350233         NaN   \n",
       "3274  5.126763  230.603758  11983.869376     6.303357         NaN   \n",
       "3275  7.874671  195.102299  17404.177061     7.509306         NaN   \n",
       "\n",
       "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "250     592.659021        8.606397        77.577460   3.875165           1  \n",
       "251     451.143481       14.770863        73.778026   3.985251           1  \n",
       "252     475.573562       12.924107        50.861913   2.747313           1  \n",
       "253     376.456593       11.432466        73.777275   3.854940           1  \n",
       "254     315.549900       14.533510        74.405616   3.939896           1  \n",
       "...            ...             ...              ...        ...         ...  \n",
       "3271    526.424171       13.894419        66.687695   4.435821           1  \n",
       "3272    392.449580       19.903225              NaN   2.798243           1  \n",
       "3273    432.044783       11.039070        69.845400   3.298875           1  \n",
       "3274    402.883113       11.168946        77.488213   4.708658           1  \n",
       "3275    327.459760       16.140368        78.698446   2.309149           1  \n",
       "\n",
       "[1278 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view data where potability = 1\n",
    "water_df.loc[water_df.Potability == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHO Standards for the potable water\n",
    "* PH between 6.50 - 8.50 pH\n",
    "* Choramines <= 4 mg/L (CDC)\n",
    "* Conductivity <=400 mueS/cm (WHO)\n",
    "* Trihalomethanes <= 80 ppm (US)\n",
    "* Solids between 500 - 1000 mg/L (WHO)\n",
    "* Organic Cabon < 2 mg/L (US)\n",
    "* Turbidity < 5 NTU (WHO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 491\n",
       "Hardness             0\n",
       "Solids               0\n",
       "Chloramines          0\n",
       "Sulfate            781\n",
       "Conductivity         0\n",
       "Organic_carbon       0\n",
       "Trihalomethanes    162\n",
       "Turbidity            0\n",
       "Potability           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copying data\n",
    "clean_water = water_df.copy()\n",
    "\n",
    "# Find any null values in the dataset\n",
    "clean_water.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ph</th>\n",
       "      <td>0.014530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hardness</th>\n",
       "      <td>-0.001505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solids</th>\n",
       "      <td>0.040674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chloramines</th>\n",
       "      <td>0.020784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sulfate</th>\n",
       "      <td>-0.015303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conductivity</th>\n",
       "      <td>-0.015496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Organic_carbon</th>\n",
       "      <td>-0.015567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <td>0.009244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turbidity</th>\n",
       "      <td>0.022682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Potability</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Potability\n",
       "ph                 0.014530\n",
       "Hardness          -0.001505\n",
       "Solids             0.040674\n",
       "Chloramines        0.020784\n",
       "Sulfate           -0.015303\n",
       "Conductivity      -0.015496\n",
       "Organic_carbon    -0.015567\n",
       "Trihalomethanes    0.009244\n",
       "Turbidity          0.022682\n",
       "Potability         1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop null values\n",
    "clean_water.dropna(inplace = True)\n",
    "\n",
    "# Find correlation with the feature potability\n",
    "clean_water.corr()[[\"Potability\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the features columns into features and target\n",
    "X = clean_water.drop('Potability', axis = 1)\n",
    "y = clean_water[\"Potability\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 45, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated Neural Network Model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation', ['relu','tanh', 'sigmoid'])\n",
    "    \n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=1,\n",
    "        max_value=30,\n",
    "        step=5), activation=activation, input_dim=9))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 4)):\n",
    "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=1,\n",
    "            max_value=30,\n",
    "            step=4),\n",
    "            activation=activation))\n",
    "    \n",
    "    # Output layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the kerastuner library\n",
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    factor = 3,\n",
    "    max_epochs=20,\n",
    "    hyperband_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 Complete [00h 00m 03s]\n",
      "val_accuracy: 0.6327543258666992\n",
      "\n",
      "Best val_accuracy So Far: 0.7022332549095154\n",
      "Total elapsed time: 00h 02m 02s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# # Run the kerastuner search for best hyperparameters\n",
    "tuner.search(X_train_scaled,y_train,epochs=20,validation_data=(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: relu\n",
      "first_units: 16\n",
      "num_layers: 3\n",
      "units_0: 13\n",
      "units_1: 5\n",
      "units_2: 17\n",
      "units_3: 5\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.7022332549095154\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: relu\n",
      "first_units: 26\n",
      "num_layers: 2\n",
      "units_0: 25\n",
      "units_1: 21\n",
      "units_2: 29\n",
      "units_3: 13\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 9e4c1717371529fa5f1b2695ff7bc366\n",
      "Score: 0.6997518539428711\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: relu\n",
      "first_units: 16\n",
      "num_layers: 2\n",
      "units_0: 9\n",
      "units_1: 21\n",
      "units_2: 17\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 95ef96b68c2c00ddf96b35f5d71661c4\n",
      "Score: 0.6947891116142273\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: relu\n",
      "first_units: 26\n",
      "num_layers: 2\n",
      "units_0: 25\n",
      "units_1: 21\n",
      "units_2: 29\n",
      "units_3: 13\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.6873449087142944\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: relu\n",
      "first_units: 16\n",
      "num_layers: 3\n",
      "units_0: 9\n",
      "units_1: 1\n",
      "units_2: 1\n",
      "units_3: 13\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.6799007654190063\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 16\n",
      "num_layers: 3\n",
      "units_0: 9\n",
      "units_1: 13\n",
      "units_2: 29\n",
      "units_3: 25\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.6774193644523621\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: relu\n",
      "first_units: 16\n",
      "num_layers: 2\n",
      "units_0: 9\n",
      "units_1: 21\n",
      "units_2: 17\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 3\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 8d1a6af960a4b35b62d4e222d671a828\n",
      "Score: 0.6724565625190735\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 16\n",
      "num_layers: 3\n",
      "units_0: 9\n",
      "units_1: 17\n",
      "units_2: 13\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: c9b9a4e2a4f650ab8f0165a81da85bfa\n",
      "Score: 0.6699751615524292\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 11\n",
      "num_layers: 2\n",
      "units_0: 13\n",
      "units_1: 17\n",
      "units_2: 5\n",
      "units_3: 17\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.6674938201904297\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: relu\n",
      "first_units: 16\n",
      "num_layers: 2\n",
      "units_0: 13\n",
      "units_1: 17\n",
      "units_2: 13\n",
      "units_3: 25\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.6674938201904297\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 11)                110       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Create first layer of input\n",
    "model.add(tf.keras.layers.Dense(units = 11, activation = 'relu', input_dim=9))\n",
    "\n",
    "# Create hidden layers \n",
    "# model.add(tf.keras.layers.Dense(units = 13, activation = 'relu'))\n",
    "# model.add(tf.keras.layers.Dense(units = 21, activation = 'tanh'))\n",
    "# model.add(tf.keras.layers.Dense(units = 13, activation = 'relu'))\n",
    "\n",
    "# Create ouput layers\n",
    "model.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Structure of sequential model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 1s 4ms/step - loss: 0.7491 - accuracy: 0.5149 - val_loss: 0.7798 - val_accuracy: 0.4848\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7229 - accuracy: 0.5283 - val_loss: 0.7632 - val_accuracy: 0.5152\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7065 - accuracy: 0.5352 - val_loss: 0.7502 - val_accuracy: 0.5455\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5543 - val_loss: 0.7418 - val_accuracy: 0.5455\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5644 - val_loss: 0.7351 - val_accuracy: 0.5758\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5810 - val_loss: 0.7273 - val_accuracy: 0.6061\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6744 - accuracy: 0.5886 - val_loss: 0.7240 - val_accuracy: 0.5758\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6700 - accuracy: 0.5873 - val_loss: 0.7175 - val_accuracy: 0.5758\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.5968 - val_loss: 0.7149 - val_accuracy: 0.5758\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.5994 - val_loss: 0.7125 - val_accuracy: 0.6061\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.6095 - val_loss: 0.7093 - val_accuracy: 0.6364\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.6140 - val_loss: 0.7064 - val_accuracy: 0.6364\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6210 - val_loss: 0.7028 - val_accuracy: 0.6364\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6279 - val_loss: 0.6974 - val_accuracy: 0.6364\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6362 - val_loss: 0.6927 - val_accuracy: 0.6364\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.6419 - val_loss: 0.6895 - val_accuracy: 0.6364\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6403 - accuracy: 0.6476 - val_loss: 0.6847 - val_accuracy: 0.6364\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.6578 - val_loss: 0.6772 - val_accuracy: 0.6061\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.6578 - val_loss: 0.6747 - val_accuracy: 0.6061\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.6654 - val_loss: 0.6699 - val_accuracy: 0.5758\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6711 - val_loss: 0.6658 - val_accuracy: 0.6364\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6692 - val_loss: 0.6609 - val_accuracy: 0.6364\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6794 - val_loss: 0.6548 - val_accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.6794 - val_loss: 0.6488 - val_accuracy: 0.6970\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.6857 - val_loss: 0.6437 - val_accuracy: 0.6970\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6883 - val_loss: 0.6400 - val_accuracy: 0.6970\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6064 - accuracy: 0.6902 - val_loss: 0.6355 - val_accuracy: 0.6970\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6032 - accuracy: 0.6927 - val_loss: 0.6312 - val_accuracy: 0.6970\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.6952 - val_loss: 0.6282 - val_accuracy: 0.6970\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.7010 - val_loss: 0.6245 - val_accuracy: 0.6970\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.7029 - val_loss: 0.6203 - val_accuracy: 0.6970\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.7048 - val_loss: 0.6176 - val_accuracy: 0.6970\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.7041 - val_loss: 0.6142 - val_accuracy: 0.6970\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.7016 - val_loss: 0.6122 - val_accuracy: 0.6970\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.7041 - val_loss: 0.6117 - val_accuracy: 0.6970\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.7035 - val_loss: 0.6128 - val_accuracy: 0.6970\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.7022 - val_loss: 0.6110 - val_accuracy: 0.6970\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.7022 - val_loss: 0.6104 - val_accuracy: 0.7273\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.6997 - val_loss: 0.6072 - val_accuracy: 0.7273\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7010 - val_loss: 0.6085 - val_accuracy: 0.7273\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.7022 - val_loss: 0.6044 - val_accuracy: 0.7273\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7016 - val_loss: 0.6051 - val_accuracy: 0.7273\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.7048 - val_loss: 0.6050 - val_accuracy: 0.7273\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7048 - val_loss: 0.6037 - val_accuracy: 0.7273\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.7041 - val_loss: 0.6037 - val_accuracy: 0.7273\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7029 - val_loss: 0.6043 - val_accuracy: 0.7273\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.7022 - val_loss: 0.6044 - val_accuracy: 0.7273\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5744 - accuracy: 0.7035 - val_loss: 0.6049 - val_accuracy: 0.7273\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7041 - val_loss: 0.6029 - val_accuracy: 0.7273\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7054 - val_loss: 0.6015 - val_accuracy: 0.7273\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7041 - val_loss: 0.5977 - val_accuracy: 0.7273\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7073 - val_loss: 0.5997 - val_accuracy: 0.7273\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7060 - val_loss: 0.6008 - val_accuracy: 0.7273\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.7048 - val_loss: 0.5990 - val_accuracy: 0.7273\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7086 - val_loss: 0.6029 - val_accuracy: 0.7273\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7060 - val_loss: 0.5981 - val_accuracy: 0.7273\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.7067 - val_loss: 0.5995 - val_accuracy: 0.6970\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7092 - val_loss: 0.6006 - val_accuracy: 0.6970\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7079 - val_loss: 0.6005 - val_accuracy: 0.6970\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7067 - val_loss: 0.6002 - val_accuracy: 0.6970\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7054 - val_loss: 0.5991 - val_accuracy: 0.6970\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7086 - val_loss: 0.5983 - val_accuracy: 0.6970\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7086 - val_loss: 0.5978 - val_accuracy: 0.6970\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7092 - val_loss: 0.5996 - val_accuracy: 0.6970\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7079 - val_loss: 0.5996 - val_accuracy: 0.6970\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7105 - val_loss: 0.5993 - val_accuracy: 0.6970\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7130 - val_loss: 0.6024 - val_accuracy: 0.6970\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7124 - val_loss: 0.6004 - val_accuracy: 0.6970\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7092 - val_loss: 0.6009 - val_accuracy: 0.6970\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7105 - val_loss: 0.6016 - val_accuracy: 0.6970\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7105 - val_loss: 0.6044 - val_accuracy: 0.6970\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7124 - val_loss: 0.6020 - val_accuracy: 0.6970\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7124 - val_loss: 0.6026 - val_accuracy: 0.6970\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7111 - val_loss: 0.6025 - val_accuracy: 0.6970\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7137 - val_loss: 0.6046 - val_accuracy: 0.6970\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7111 - val_loss: 0.6005 - val_accuracy: 0.6970\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7117 - val_loss: 0.6070 - val_accuracy: 0.6970\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7130 - val_loss: 0.6017 - val_accuracy: 0.6970\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7105 - val_loss: 0.6036 - val_accuracy: 0.6970\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7130 - val_loss: 0.5994 - val_accuracy: 0.6970\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7130 - val_loss: 0.6019 - val_accuracy: 0.6970\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7143 - val_loss: 0.6027 - val_accuracy: 0.6970\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7124 - val_loss: 0.6026 - val_accuracy: 0.6970\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7117 - val_loss: 0.6013 - val_accuracy: 0.6970\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7137 - val_loss: 0.6034 - val_accuracy: 0.6970\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7117 - val_loss: 0.6006 - val_accuracy: 0.6970\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7124 - val_loss: 0.6020 - val_accuracy: 0.6970\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7130 - val_loss: 0.5995 - val_accuracy: 0.6970\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7130 - val_loss: 0.6051 - val_accuracy: 0.6970\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7137 - val_loss: 0.6009 - val_accuracy: 0.6970\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7124 - val_loss: 0.6005 - val_accuracy: 0.6970\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7156 - val_loss: 0.6028 - val_accuracy: 0.6970\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7149 - val_loss: 0.6013 - val_accuracy: 0.6970\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7149 - val_loss: 0.6028 - val_accuracy: 0.6970\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7162 - val_loss: 0.6027 - val_accuracy: 0.6970\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7156 - val_loss: 0.6010 - val_accuracy: 0.6970\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7137 - val_loss: 0.6007 - val_accuracy: 0.6970\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7175 - val_loss: 0.6007 - val_accuracy: 0.6970\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7175 - val_loss: 0.5999 - val_accuracy: 0.6970\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7143 - val_loss: 0.6025 - val_accuracy: 0.6970\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "# lr = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, name='Adam')\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "fit_model = model.fit(X_train_scaled, y_train, epochs = 100, validation_split=0.02) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 - 0s - loss: 0.5622 - accuracy: 0.7158\n",
      "Tain Loss: 0.562157928943634, Train Accuracy: 0.7157959938049316\n",
      "13/13 - 0s - loss: 0.5681 - accuracy: 0.7196\n",
      "Test Loss: 0.5680698752403259, Test Accuracy: 0.7196030020713806\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = model.evaluate(X_train_scaled,y_train,verbose=2)\n",
    "print(f\"Tain Loss: {model_loss}, Train Accuracy: {model_accuracy}\")\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Test Loss: {model_loss}, Test Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the accuracy\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.5970149253731343\n",
      "Testing Data Score: 0.6401985111662531\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "print(f\"Training Data Score: {lr.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {lr.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
