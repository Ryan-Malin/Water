{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file and load\n",
    "water_df = pd.read_csv(\"water_potability.csv\")\n",
    "water_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3276 entries, 0 to 3275\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ph               2785 non-null   float64\n",
      " 1   Hardness         3276 non-null   float64\n",
      " 2   Solids           3276 non-null   float64\n",
      " 3   Chloramines      3276 non-null   float64\n",
      " 4   Sulfate          2495 non-null   float64\n",
      " 5   Conductivity     3276 non-null   float64\n",
      " 6   Organic_carbon   3276 non-null   float64\n",
      " 7   Trihalomethanes  3114 non-null   float64\n",
      " 8   Turbidity        3276 non-null   float64\n",
      " 9   Potability       3276 non-null   int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 256.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Know about the dataset\n",
    "water_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1998\n",
       "1    1278\n",
       "Name: Potability, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Potability value count\n",
    "label_count = water_df[\"Potability\"].value_counts() \n",
    "label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>9.445130</td>\n",
       "      <td>145.805402</td>\n",
       "      <td>13168.529156</td>\n",
       "      <td>9.444471</td>\n",
       "      <td>310.583374</td>\n",
       "      <td>592.659021</td>\n",
       "      <td>8.606397</td>\n",
       "      <td>77.577460</td>\n",
       "      <td>3.875165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>9.024845</td>\n",
       "      <td>128.096691</td>\n",
       "      <td>19859.676476</td>\n",
       "      <td>8.016423</td>\n",
       "      <td>300.150377</td>\n",
       "      <td>451.143481</td>\n",
       "      <td>14.770863</td>\n",
       "      <td>73.778026</td>\n",
       "      <td>3.985251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>NaN</td>\n",
       "      <td>169.974849</td>\n",
       "      <td>23403.637304</td>\n",
       "      <td>8.519730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>475.573562</td>\n",
       "      <td>12.924107</td>\n",
       "      <td>50.861913</td>\n",
       "      <td>2.747313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>6.800119</td>\n",
       "      <td>242.008082</td>\n",
       "      <td>39143.403329</td>\n",
       "      <td>9.501695</td>\n",
       "      <td>187.170714</td>\n",
       "      <td>376.456593</td>\n",
       "      <td>11.432466</td>\n",
       "      <td>73.777275</td>\n",
       "      <td>3.854940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>7.174135</td>\n",
       "      <td>203.408935</td>\n",
       "      <td>20401.102461</td>\n",
       "      <td>7.681806</td>\n",
       "      <td>287.085679</td>\n",
       "      <td>315.549900</td>\n",
       "      <td>14.533510</td>\n",
       "      <td>74.405616</td>\n",
       "      <td>3.939896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>4.668102</td>\n",
       "      <td>193.681735</td>\n",
       "      <td>47580.991603</td>\n",
       "      <td>7.166639</td>\n",
       "      <td>359.948574</td>\n",
       "      <td>526.424171</td>\n",
       "      <td>13.894419</td>\n",
       "      <td>66.687695</td>\n",
       "      <td>4.435821</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>7.808856</td>\n",
       "      <td>193.553212</td>\n",
       "      <td>17329.802160</td>\n",
       "      <td>8.061362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>392.449580</td>\n",
       "      <td>19.903225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.798243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>9.419510</td>\n",
       "      <td>175.762646</td>\n",
       "      <td>33155.578218</td>\n",
       "      <td>7.350233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>432.044783</td>\n",
       "      <td>11.039070</td>\n",
       "      <td>69.845400</td>\n",
       "      <td>3.298875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>5.126763</td>\n",
       "      <td>230.603758</td>\n",
       "      <td>11983.869376</td>\n",
       "      <td>6.303357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>402.883113</td>\n",
       "      <td>11.168946</td>\n",
       "      <td>77.488213</td>\n",
       "      <td>4.708658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>7.874671</td>\n",
       "      <td>195.102299</td>\n",
       "      <td>17404.177061</td>\n",
       "      <td>7.509306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>327.459760</td>\n",
       "      <td>16.140368</td>\n",
       "      <td>78.698446</td>\n",
       "      <td>2.309149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1278 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
       "250   9.445130  145.805402  13168.529156     9.444471  310.583374   \n",
       "251   9.024845  128.096691  19859.676476     8.016423  300.150377   \n",
       "252        NaN  169.974849  23403.637304     8.519730         NaN   \n",
       "253   6.800119  242.008082  39143.403329     9.501695  187.170714   \n",
       "254   7.174135  203.408935  20401.102461     7.681806  287.085679   \n",
       "...        ...         ...           ...          ...         ...   \n",
       "3271  4.668102  193.681735  47580.991603     7.166639  359.948574   \n",
       "3272  7.808856  193.553212  17329.802160     8.061362         NaN   \n",
       "3273  9.419510  175.762646  33155.578218     7.350233         NaN   \n",
       "3274  5.126763  230.603758  11983.869376     6.303357         NaN   \n",
       "3275  7.874671  195.102299  17404.177061     7.509306         NaN   \n",
       "\n",
       "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "250     592.659021        8.606397        77.577460   3.875165           1  \n",
       "251     451.143481       14.770863        73.778026   3.985251           1  \n",
       "252     475.573562       12.924107        50.861913   2.747313           1  \n",
       "253     376.456593       11.432466        73.777275   3.854940           1  \n",
       "254     315.549900       14.533510        74.405616   3.939896           1  \n",
       "...            ...             ...              ...        ...         ...  \n",
       "3271    526.424171       13.894419        66.687695   4.435821           1  \n",
       "3272    392.449580       19.903225              NaN   2.798243           1  \n",
       "3273    432.044783       11.039070        69.845400   3.298875           1  \n",
       "3274    402.883113       11.168946        77.488213   4.708658           1  \n",
       "3275    327.459760       16.140368        78.698446   2.309149           1  \n",
       "\n",
       "[1278 rows x 10 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view data where potability = 1\n",
    "water_df.loc[water_df.Potability == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHO Standards for the potable water\n",
    "* PH between 6.50 - 8.50 pH\n",
    "* Choramines <= 4 mg/L (CDC)\n",
    "* Conductivity <=400 mueS/cm (WHO)\n",
    "* Trihalomethanes <= 80 ppm (US)\n",
    "* Solids between 500 - 1000 mg/L (WHO)\n",
    "* Organic Cabon < 2 mg/L (US)\n",
    "* Turbidity < 5 NTU (WHO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 491\n",
       "Hardness             0\n",
       "Solids               0\n",
       "Chloramines          0\n",
       "Sulfate            781\n",
       "Conductivity         0\n",
       "Organic_carbon       0\n",
       "Trihalomethanes    162\n",
       "Turbidity            0\n",
       "Potability           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copying data\n",
    "clean_water = water_df.copy()\n",
    "\n",
    "# Find any null values in the dataset\n",
    "clean_water.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ph</th>\n",
       "      <td>0.014530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hardness</th>\n",
       "      <td>-0.001505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solids</th>\n",
       "      <td>0.040674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chloramines</th>\n",
       "      <td>0.020784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sulfate</th>\n",
       "      <td>-0.015303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conductivity</th>\n",
       "      <td>-0.015496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Organic_carbon</th>\n",
       "      <td>-0.015567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <td>0.009244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turbidity</th>\n",
       "      <td>0.022682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Potability</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Potability\n",
       "ph                 0.014530\n",
       "Hardness          -0.001505\n",
       "Solids             0.040674\n",
       "Chloramines        0.020784\n",
       "Sulfate           -0.015303\n",
       "Conductivity      -0.015496\n",
       "Organic_carbon    -0.015567\n",
       "Trihalomethanes    0.009244\n",
       "Turbidity          0.022682\n",
       "Potability         1.000000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop null values\n",
    "clean_water.dropna(inplace = True)\n",
    "\n",
    "# Find correlation with the feature potability\n",
    "clean_water.corr()[[\"Potability\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the features columns into features and target\n",
    "X = clean_water.drop('Potability', axis = 1)\n",
    "y = clean_water[\"Potability\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 45, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated Neural Network Model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation', ['relu','tanh', 'sigmoid'])\n",
    "    \n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=1,\n",
    "        max_value=30,\n",
    "        step=5), activation=activation, input_dim=9))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 5)):\n",
    "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=1,\n",
    "            max_value=30,\n",
    "            step=4),\n",
    "            activation=activation))\n",
    "    \n",
    "    # Output layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\untitled_project\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Import the kerastuner library\n",
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    factor = 3,\n",
    "    max_epochs=20,\n",
    "    hyperband_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 Complete [00h 00m 04s]\n",
      "val_accuracy: 0.6724565625190735\n",
      "\n",
      "Best val_accuracy So Far: 0.7394540905952454\n",
      "Total elapsed time: 00h 02m 04s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# # Run the kerastuner search for best hyperparameters\n",
    "tuner.search(X_train_scaled,y_train,epochs=20,validation_data=(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: relu\n",
      "first_units: 26\n",
      "num_layers: 2\n",
      "units_0: 21\n",
      "units_1: 17\n",
      "units_2: 13\n",
      "units_3: 9\n",
      "units_4: 9\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 4e17b2c70b4c3327c6fcf9e240ff7498\n",
      "Score: 0.7394540905952454\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: relu\n",
      "first_units: 26\n",
      "num_layers: 3\n",
      "units_0: 25\n",
      "units_1: 21\n",
      "units_2: 25\n",
      "units_3: 17\n",
      "units_4: 13\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.7121587991714478\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 26\n",
      "num_layers: 3\n",
      "units_0: 29\n",
      "units_1: 29\n",
      "units_2: 13\n",
      "units_3: 29\n",
      "units_4: 13\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: e528a4e140ca787aa419020339ef7a4e\n",
      "Score: 0.7096773982048035\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: relu\n",
      "first_units: 11\n",
      "num_layers: 1\n",
      "units_0: 13\n",
      "units_1: 9\n",
      "units_2: 29\n",
      "units_3: 1\n",
      "units_4: 25\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: d1aee9d6c3f1613b163761e5b79b0c18\n",
      "Score: 0.7022332549095154\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: relu\n",
      "first_units: 26\n",
      "num_layers: 2\n",
      "units_0: 21\n",
      "units_1: 17\n",
      "units_2: 13\n",
      "units_3: 9\n",
      "units_4: 9\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.6972704529762268\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: relu\n",
      "first_units: 26\n",
      "num_layers: 3\n",
      "units_0: 25\n",
      "units_1: 21\n",
      "units_2: 25\n",
      "units_3: 17\n",
      "units_4: 13\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: d3be2aa43ff04b2a2c73fa3724826318\n",
      "Score: 0.6972704529762268\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 26\n",
      "num_layers: 2\n",
      "units_0: 21\n",
      "units_1: 21\n",
      "units_2: 21\n",
      "units_3: 13\n",
      "units_4: 17\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 4b42d5d37a58c36b6c19434dee654b56\n",
      "Score: 0.6724565625190735\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 21\n",
      "num_layers: 2\n",
      "units_0: 9\n",
      "units_1: 25\n",
      "units_2: 25\n",
      "units_3: 9\n",
      "units_4: 5\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.6724565625190735\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 26\n",
      "num_layers: 4\n",
      "units_0: 25\n",
      "units_1: 13\n",
      "units_2: 1\n",
      "units_3: 5\n",
      "units_4: 21\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: f2668f45f76c123c2148d009fd0798af\n",
      "Score: 0.6674938201904297\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 6\n",
      "num_layers: 4\n",
      "units_0: 5\n",
      "units_1: 9\n",
      "units_2: 17\n",
      "units_3: 1\n",
      "units_4: 25\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 105a5b9e7eb948a00aa521a1d1587156\n",
      "Score: 0.6650124192237854\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 11)                110       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Create first layer of input\n",
    "model.add(tf.keras.layers.Dense(units = 11, activation = 'relu', input_dim=9))\n",
    "\n",
    "# Create hidden layers \n",
    "# model.add(tf.keras.layers.Dense(units = 17, activation = 'relu'))\n",
    "# model.add(tf.keras.layers.Dense(units = 21, activation = 'relu'))\n",
    "# model.add(tf.keras.layers.Dense(units = 25, activation = 'relu'))\n",
    "\n",
    "# Create ouput layers\n",
    "model.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Structure of sequential model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 1s 6ms/step - loss: 0.7924 - accuracy: 0.5238 - val_loss: 0.6973 - val_accuracy: 0.6061\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7554 - accuracy: 0.5352 - val_loss: 0.6822 - val_accuracy: 0.6061\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7299 - accuracy: 0.5435 - val_loss: 0.6729 - val_accuracy: 0.6061\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7121 - accuracy: 0.5543 - val_loss: 0.6706 - val_accuracy: 0.5758\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6992 - accuracy: 0.5714 - val_loss: 0.6690 - val_accuracy: 0.5758\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5790 - val_loss: 0.6676 - val_accuracy: 0.5455\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5784 - val_loss: 0.6687 - val_accuracy: 0.5455\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6757 - accuracy: 0.5784 - val_loss: 0.6700 - val_accuracy: 0.5152\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.5740 - val_loss: 0.6707 - val_accuracy: 0.5152\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.5778 - val_loss: 0.6735 - val_accuracy: 0.5152\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.5917 - val_loss: 0.6722 - val_accuracy: 0.5152\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.5911 - val_loss: 0.6731 - val_accuracy: 0.5152\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.5968 - val_loss: 0.6721 - val_accuracy: 0.5152\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6032 - val_loss: 0.6699 - val_accuracy: 0.5152\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6089 - val_loss: 0.6686 - val_accuracy: 0.5152\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.6114 - val_loss: 0.6682 - val_accuracy: 0.5152\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.6133 - val_loss: 0.6656 - val_accuracy: 0.5455\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.6184 - val_loss: 0.6640 - val_accuracy: 0.5455\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.6235 - val_loss: 0.6633 - val_accuracy: 0.5152\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6273 - val_loss: 0.6600 - val_accuracy: 0.5152\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.6311 - val_loss: 0.6605 - val_accuracy: 0.4848\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.6375 - val_loss: 0.6583 - val_accuracy: 0.4545\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.6368 - val_loss: 0.6591 - val_accuracy: 0.5152\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6406 - val_loss: 0.6578 - val_accuracy: 0.5758\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6419 - val_loss: 0.6559 - val_accuracy: 0.5455\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6470 - val_loss: 0.6591 - val_accuracy: 0.5455\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.6502 - val_loss: 0.6570 - val_accuracy: 0.5152\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6502 - val_loss: 0.6569 - val_accuracy: 0.5455\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6552 - val_loss: 0.6546 - val_accuracy: 0.5455\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6552 - val_loss: 0.6554 - val_accuracy: 0.5758\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6540 - val_loss: 0.6570 - val_accuracy: 0.5758\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.6641 - val_loss: 0.6557 - val_accuracy: 0.5758\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.6590 - val_loss: 0.6578 - val_accuracy: 0.5758\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6610 - val_loss: 0.6580 - val_accuracy: 0.6061\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.6641 - val_loss: 0.6574 - val_accuracy: 0.6061\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.6616 - val_loss: 0.6585 - val_accuracy: 0.6364\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6686 - val_loss: 0.6564 - val_accuracy: 0.6061\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6635 - val_loss: 0.6578 - val_accuracy: 0.6364\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6060 - accuracy: 0.6673 - val_loss: 0.6597 - val_accuracy: 0.6364\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.6679 - val_loss: 0.6595 - val_accuracy: 0.6364\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.6673 - val_loss: 0.6575 - val_accuracy: 0.6364\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.6711 - val_loss: 0.6593 - val_accuracy: 0.6364\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.6781 - val_loss: 0.6544 - val_accuracy: 0.6364\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.6743 - val_loss: 0.6575 - val_accuracy: 0.6364\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.6756 - val_loss: 0.6579 - val_accuracy: 0.6364\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.6800 - val_loss: 0.6584 - val_accuracy: 0.6364\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.6813 - val_loss: 0.6571 - val_accuracy: 0.6364\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5973 - accuracy: 0.6825 - val_loss: 0.6609 - val_accuracy: 0.6364\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.6794 - val_loss: 0.6605 - val_accuracy: 0.6364\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6825 - val_loss: 0.6592 - val_accuracy: 0.6364\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.6832 - val_loss: 0.6613 - val_accuracy: 0.6364\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5940 - accuracy: 0.6883 - val_loss: 0.6631 - val_accuracy: 0.6364\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.6832 - val_loss: 0.6640 - val_accuracy: 0.6364\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.6857 - val_loss: 0.6619 - val_accuracy: 0.6364\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.6857 - val_loss: 0.6619 - val_accuracy: 0.6364\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.6876 - val_loss: 0.6601 - val_accuracy: 0.6364\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.6933 - val_loss: 0.6599 - val_accuracy: 0.6364\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.6895 - val_loss: 0.6623 - val_accuracy: 0.6667\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.6902 - val_loss: 0.6617 - val_accuracy: 0.6667\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.6940 - val_loss: 0.6594 - val_accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.6946 - val_loss: 0.6601 - val_accuracy: 0.6667\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.6921 - val_loss: 0.6625 - val_accuracy: 0.6667\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.6952 - val_loss: 0.6625 - val_accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.6940 - val_loss: 0.6646 - val_accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.6946 - val_loss: 0.6644 - val_accuracy: 0.6667\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.6933 - val_loss: 0.6632 - val_accuracy: 0.6667\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.6959 - val_loss: 0.6638 - val_accuracy: 0.6667\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5811 - accuracy: 0.70 - 0s 2ms/step - loss: 0.5847 - accuracy: 0.6978 - val_loss: 0.6677 - val_accuracy: 0.6667\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.6984 - val_loss: 0.6659 - val_accuracy: 0.6667\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.6990 - val_loss: 0.6637 - val_accuracy: 0.6667\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.6984 - val_loss: 0.6663 - val_accuracy: 0.6970\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.6978 - val_loss: 0.6654 - val_accuracy: 0.6970\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.6978 - val_loss: 0.6635 - val_accuracy: 0.6970\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.6978 - val_loss: 0.6655 - val_accuracy: 0.6970\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.6990 - val_loss: 0.6656 - val_accuracy: 0.6970\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7016 - val_loss: 0.6630 - val_accuracy: 0.6970\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.6971 - val_loss: 0.6655 - val_accuracy: 0.6970\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.7016 - val_loss: 0.6652 - val_accuracy: 0.6970\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7003 - val_loss: 0.6659 - val_accuracy: 0.6970\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.7054 - val_loss: 0.6694 - val_accuracy: 0.6970\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.7010 - val_loss: 0.6684 - val_accuracy: 0.6970\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7029 - val_loss: 0.6673 - val_accuracy: 0.6970\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7054 - val_loss: 0.6636 - val_accuracy: 0.6970\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.7022 - val_loss: 0.6681 - val_accuracy: 0.6970\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.7029 - val_loss: 0.6620 - val_accuracy: 0.6970\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.7048 - val_loss: 0.6590 - val_accuracy: 0.6970\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7035 - val_loss: 0.6621 - val_accuracy: 0.6970\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.7022 - val_loss: 0.6617 - val_accuracy: 0.6970\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7054 - val_loss: 0.6648 - val_accuracy: 0.6970\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7060 - val_loss: 0.6626 - val_accuracy: 0.6970\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7041 - val_loss: 0.6635 - val_accuracy: 0.6970\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7060 - val_loss: 0.6616 - val_accuracy: 0.6970\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7035 - val_loss: 0.6603 - val_accuracy: 0.6970\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.7016 - val_loss: 0.6635 - val_accuracy: 0.6970\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7073 - val_loss: 0.6654 - val_accuracy: 0.6970\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7054 - val_loss: 0.6636 - val_accuracy: 0.6970\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7041 - val_loss: 0.6627 - val_accuracy: 0.6970\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7086 - val_loss: 0.6613 - val_accuracy: 0.6970\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7041 - val_loss: 0.6617 - val_accuracy: 0.6970\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7073 - val_loss: 0.6621 - val_accuracy: 0.6970\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "# lr = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, name='Adam')\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "fit_model = model.fit(X_train_scaled, y_train, epochs = 100, validation_split=0.02) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 - 0s - loss: 0.5720 - accuracy: 0.7058\n",
      "Tain Loss: 0.5719649791717529, Train Accuracy: 0.7058457732200623\n",
      "13/13 - 0s - loss: 0.5752 - accuracy: 0.7171\n",
      "Test Loss: 0.5751603245735168, Test Accuracy: 0.7171216011047363\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = model.evaluate(X_train_scaled,y_train,verbose=2)\n",
    "print(f\"Tain Loss: {model_loss}, Train Accuracy: {model_accuracy}\")\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Test Loss: {model_loss}, Test Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the accuracy\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.5970149253731343\n",
      "Testing Data Score: 0.6401985111662531\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "print(f\"Training Data Score: {lr.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {lr.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
